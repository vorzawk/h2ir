{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2018\n",
    "\n",
    "\n",
    "# Homework 2:  Link Analysis -- HITS + SEO\n",
    "\n",
    "### 100 points [5% of your final grade]\n",
    "\n",
    "### Due: Sunday, February 25, 2018 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* Explore real-world challenges of building a graph (in this case, from tweets), implement and test HITS algortihm over this graph, and investigate factors that impact a page's rank on Google and Bing.\n",
    "\n",
    "*Submission Instructions:* To submit your homework, rename this notebook as YOUR_UIN_hw2.ipynb. Submit this notebook via ecampus. Your notebook should be completely self-contained, with the results visible in the notebook. \n",
    "\n",
    "*Late submission policy:* For this homework, you may use up to three of your late days, meaning that no submissions will be accepted after Wednesday, February 28, 2018 at 11:59pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: HITS (70 points)\n",
    "\n",
    "## A re-Tweet Graph\n",
    "\n",
    "In this assignment, we're going to adapt the classic HITS approach to allow us to find not the most authoritative web pages, but rather to find significant Twitter users. So, instead of viewing the world as web pages with hyperlinks (where pages = nodes, hyperlinks = edges), we're going to construct a graph of Twitter users and their retweets of other Twitter users (so user = node, retweet of another user = edge). Over this Twitter-user graph, we can apply the HITS approach to order the users by their hub-ness and their authority-ness.\n",
    "\n",
    "Here is a toy example. Suppose you are given the following four retweets:\n",
    "\n",
    "* **userID**: diane, **text**: \"RT \", **sourceID**: bob\n",
    "* **userID**: charlie, **text**: \"RT Welcome\", **sourceID**: alice\n",
    "* **userID**: bob, **text**: \"RT Hi \", **sourceID**: diane\n",
    "* **userID**: alice, **text**: \"RT Howdy!\", **sourceID**: parisa\n",
    "\n",
    "There are four short tweets retweeted by four users. The retweet between users form a directed graph with five nodes and four edges. E.g., the \"diane\" node has a directed edge to the \"bob\" node.\n",
    "\n",
    "You should build a graph by parsing the tweets in the file we provide called *HITS.json*.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* You may see some weird characters in the content of tweets, just ignore them. \n",
    "* The edges are weighted and directed. If Bob retweets Alice's tweets 10 times, there is an edge from Bob to Alice with weight 10, but there is not an edge from Alice to Bob.\n",
    "* If a user retweets herself, ignore it.\n",
    "* Correctly parsing screen_name in a tweet is error-prone. Use the id of the user (this is the user who is re-tweeting) and the id of the user in the retweeted_status field (this is the user who is being re-tweeted; that is, this user created the original tweet).\n",
    "* Later you will need to implement the HITS algorithm on the graph you build here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 1], [3084868798, 2794076279, 3033425707, 3052705430], [3068706044, 3065514742, 3058557188, 3039321886])\n",
      "  (3084868798, 3068706044)\t1\n",
      "  (2794076279, 3065514742)\t1\n",
      "  (3033425707, 3058557188)\t1\n",
      "  (3052705430, 3039321886)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4000000000x4000000000 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 4 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the graph by parsing HITS.json, this gives us A\n",
    "# The retweets are provided in the form of json data, we need to extract the userId and sourceId.\n",
    "# userId refers to the user who retweets and sourceId refers to the user who posted the original tweet\n",
    "import json\n",
    "from scipy.sparse import coo_matrix\n",
    "dictEdges = {}\n",
    "with open('HITS_small.json') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        userId = data['user']['id']\n",
    "        sourceId = data['retweeted_status']['user']['id']\n",
    "        # Retweeting is like linking to a web page, so add an edge from userId to sourceId\n",
    "        # create a dictionary of edges, dictEdges[(userId,sourceId)] = # of times userId retweets sourceId\n",
    "        if (userId,sourceId) in dictEdges.keys():\n",
    "            dictEdges[(userId,sourceId)] += 1\n",
    "        else:\n",
    "            dictEdges[(userId,sourceId)] = 1\n",
    "# print(dictEdges.keys())\n",
    "\n",
    "# To initialize a csr_matrix, we need 3 lists such that a[row_ind[k], col_ind[k]] = data[k]\n",
    "# Convert the dictionary into the form represented above by iterating over the keys\n",
    "row_ind = []\n",
    "col_ind = []\n",
    "data = []\n",
    "for (userId, sourceId) in dictEdges.keys():\n",
    "    row_ind.append(userId)\n",
    "    col_ind.append(sourceId)\n",
    "    data.append(dictEdges[(userId,sourceId)])\n",
    "print(data,row_ind,col_ind)\n",
    "A = coo_matrix((data,(row_ind,col_ind)), shape=(4000000000, 4000000000))\n",
    "print(A)\n",
    "A\n",
    "# Represent the graph as a sparse matrix indexed by the ids (not possible in dense matrix form)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not check the correctness of your graph. However, this will affect the HITS results later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HITS Implementation\n",
    "\n",
    "Your program will return the top 10 users with highest hub and authority scores. The **output** should be like:\n",
    "\n",
    "Hub Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "Authority Scores\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "You should follow these **rules**:\n",
    "\n",
    "* Assume all nodes start out with equal scores.\n",
    "* It is up to you to decide when to terminate the HITS calculation.\n",
    "* There are HITS implementations out there on the web. Remember, your code should be **your own**.\n",
    "\n",
    "\n",
    "**Hints**:\n",
    "* If you're using the matrix style approach, you should use [numpy.matrix](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html).\n",
    "* Scipy is built on top of Numpy and has support for sparse matrices. You most likely will not need to use Scipy unless you'd like to try out their sparse matrices.\n",
    "* If you choose to use Numpy (and Scipy), please make sure your Anaconda environment include their latest versions.\n",
    "* Test your parsing and HITS calculations using a handful of tweets, before moving on to the entire file we provide.\n",
    "* We will evaluate the user ranks you provide as well as the quality of your code. So make sure that your code is clear and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (3084868798, 3068706044)\t1\n",
      "  (2794076279, 3065514742)\t1\n",
      "  (3033425707, 3058557188)\t1\n",
      "  (3052705430, 3039321886)\t1\n",
      "(<4000000000x1 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 8 stored elements in COOrdinate format>, <4000000000x1 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 8 stored elements in COOrdinate format>)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-03777e0db026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mHITS_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-03777e0db026>\u001b[0m in \u001b[0;36mHITS_sparse\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_trans\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mh_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhilash/miniconda2/envs/cs670/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhilash/miniconda2/envs/cs670/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# other * self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhilash/miniconda2/envs/cs670/lib/python2.7/site-packages/scipy/sparse/coo.pyc\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# h and a are the hub scores and authority scores\n",
    "# h = Aa, a = A'h, h = AA'h and a = A'Aa till convergence\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def HITS_dense(A):\n",
    "    numUsers = A.shape[1]\n",
    "    print(numUsers)\n",
    "    A_trans = A.transpose()\n",
    "    # This results in a memory Error while using sparse matrices coz this requests a dense matrix of size \n",
    "    # 4 billion!\n",
    "    h = np.matrix(np.ones(shape=(numUsers,1)))\n",
    "    h_old = np.matrix(np.ones(shape=(numUsers,1)))\n",
    "    a = np.matrix(np.ones(shape=(numUsers,1)))\n",
    "    a_old = np.matrix(np.ones(shape=(numUsers,1)))\n",
    "    \n",
    "    \n",
    "    for _ in range(1000):\n",
    "        h = A.dot(a_old)\n",
    "        a = A_trans.dot(h_old)\n",
    "        h_old = h\n",
    "        a_old = a\n",
    "    print(\"h:\")\n",
    "    print(h)\n",
    "    print(\"a:\")\n",
    "    print(a)\n",
    "    \n",
    "# A = np.matrix([[0,1],[0,0]])\n",
    "# A = coo_matrix([[0,1],[0,0]])\n",
    "\n",
    "def HITS_sparse(A):\n",
    "    A_trans = A.transpose()\n",
    "    setUsers = set(A.row)\n",
    "    setUsers = setUsers.union(list(A.col))\n",
    "    # print(setUsers)\n",
    "    numUsers = len(setUsers)\n",
    "    row_ind = list(setUsers)\n",
    "    col_ind = np.zeros(numUsers)\n",
    "    data = np.ones(numUsers)\n",
    "    h_old = coo_matrix((data, (row_ind,col_ind)), shape=(4000000000,1))\n",
    "    a_old = coo_matrix((data, (row_ind,col_ind)), shape=(4000000000,1))\n",
    "    print(h_old, a_old)\n",
    "    for _ in range(1000):\n",
    "        h = A*a_old\n",
    "        a = A_trans*h_old\n",
    "        h_old = h\n",
    "        a_old = a\n",
    "    print(\"h:\")\n",
    "    print(h)\n",
    "    print(\"a:\")\n",
    "    print(a)\n",
    "\n",
    "print(A)\n",
    "HITS_sparse(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Search Engine Optimization (30 + 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, your goal is to put on your \"[search engine optimization](https://en.wikipedia.org/wiki/Search_engine_optimization)\" hat. Your job is to create a webpage that scores highest for the query: **kbeznak parmatonic** --- two terms, lower case, no quote. As of today (Feb 16, 2018), there are no hits for this query on either Google or Bing. Based on our discussions of search engine ranking algorithms, you know that several factors may impact a page's rank. Your goal is to use this knowledge to promote your own page to the top of the list.\n",
    "\n",
    "What we're doing here is a form of [SEO contest](https://en.wikipedia.org/wiki/SEO_contest). While you have great latitude in how you approach this problem, you are not allowed to engage in any unethical or illegal behavior. Please read the discussion of \"white hat\" versus \"black hat\" SEO over at [Wikipedia](https://en.wikipedia.org/wiki/Search_engine_optimization#White_hat_versus_black_hat_techniques).\n",
    "\n",
    "\n",
    "**Rules of the game:**\n",
    "\n",
    "* Somewhere in the page (possibly in the non-viewable source html) you must include your name or some other way for us to identify you (e.g., your NetID, but not the UIN!).\n",
    "* Your target page may only be a TAMU student page, a page on your own webserver, a page on a standard blog platform (e.g., wordpress), or some other primarily user-controlled page\n",
    "* Your target page CAN NOT be a twitter account, a facebook page, a Yahoo Answers or similar page\n",
    "* No wikipedia vandalism\n",
    "* No yahoo/wiki answers questions\n",
    "* No comment spamming of blogs\n",
    "* If you have concerns/questions/clarifications, please post on Piazza and we will discuss\n",
    "\n",
    "For your homework turnin for this part, you should provide us the URL of your target page and a brief discussion (2-4 paragraphs) of the strategies you are using. We will issue the query and check the rankings at some undetermined time in the next couple of weeks. You might guess that major search engines take some time to discover and integrate new pages: if I were you, I'd get a target page up immediately.\n",
    "\n",
    "**Grading:**\n",
    "\n",
    "* 5 points for providing a valid URL\n",
    "* 20 points for a well-reasoned discussion of your strategy\n",
    "* 5 points for your page appearing in the search results by Google or Bing (no matter how is the ranking)\n",
    "\n",
    "** Bonus: **\n",
    "* 1 point for your page appearing in the top-20 on Google or Bing\n",
    "* 1 more point for your page appearing in the top-10 on Google or Bing\n",
    "* 1 more point for your page appearing in the top-5 on Google or Bing\n",
    "* 2 more points for your page being ranked first by Google or Bing. And, a vigorous announcement in class, and a high-five for having the top result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the URL of your page?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's your strategy? (2-4 paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
